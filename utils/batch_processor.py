import os
import shutil
from typing import List, Dict
from datetime import datetime

from .archive_handler import ArchiveHandler
from .domain_detector import DomainDetector
from .domain_generator import DomainGenerator
from .file_processor import FileProcessor
from .site_name_replacer import SiteNameReplacer


class BatchProcessor:
    """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∞—Ä—Ö–∏–≤–æ–≤"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞"""
        self.archive_handler = ArchiveHandler()
        self.domain_detector = DomainDetector()
        self.domain_generator = DomainGenerator()
        self.file_processor = FileProcessor()
        self.site_name_replacer = SiteNameReplacer()
        
    def process_single_archive(self, archive_path: str, copies_count: int, 
                               domain_zone: str, temp_base_dir: str,
                               progress_callback=None) -> Dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –∫–æ–ø–∏–π
        
        Args:
            archive_path: –ø—É—Ç—å –∫ –∞—Ä—Ö–∏–≤—É
            copies_count: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ø–∏–π
            domain_zone: –¥–æ–º–µ–Ω–Ω–∞—è –∑–æ–Ω–∞ (.com, .info –∏ —Ç.–¥.)
            temp_base_dir: –±–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            progress_callback: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            
        Returns:
            dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        result = {
            'success': False,
            'archive_name': os.path.basename(archive_path),
            'original_domain': None,
            'generated_archives': [],
            'error': None,
            'stats': {}
        }
        
        archive_name = os.path.basename(archive_path)
        
        try:
            if progress_callback:
                progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {archive_name}: —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞...")
            
            # 1. –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –∞—Ä—Ö–∏–≤–∞
            archive_temp_dir = os.path.join(temp_base_dir, f"archive_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}")
            extract_dir = os.path.join(archive_temp_dir, "extracted")
            
            # 2. –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤
            if not self.archive_handler.extract_archive(archive_path, extract_dir):
                result['error'] = '–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä—Ö–∏–≤–∞'
                return result
            
            if progress_callback:
                progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {archive_name}: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ–º–µ–Ω–∞...")
            
            # 3. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –¥–æ–º–µ–Ω
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞ (–≤—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç!)
            domain_from_filename = self.domain_detector.extract_domain_from_filename(archive_name)
            
            if domain_from_filename and '.' in domain_from_filename:
                # –ü–æ–ª–Ω—ã–π –¥–æ–º–µ–Ω –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∞—Ä—Ö–∏–≤–∞ (example.com) - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
                original_domain = domain_from_filename
                if progress_callback:
                    progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {archive_name}: –¥–æ–º–µ–Ω –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è: {original_domain}")
            else:
                # –õ–∏–±–æ –Ω–µ—Ç –¥–æ–º–µ–Ω–∞, –ª–∏–±–æ —Ç–æ–ª—å–∫–æ –ø–æ–¥—Å–∫–∞–∑–∫–∞ (dimvital)
                hint = domain_from_filename if domain_from_filename else None
                
                if progress_callback and hint:
                    progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {archive_name}: –ø–æ–∏—Å–∫ —Å –ø–æ–¥—Å–∫–∞–∑–∫–æ–π '{hint}'...")
                
                # –ò—â–µ–º –≤ —Ñ–∞–π–ª–∞—Ö —Å–∞–π—Ç–∞ —Å –ø–æ–¥—Å–∫–∞–∑–∫–æ–π –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
                original_domain = self.domain_detector.detect_domain_in_directory(extract_dir, hint_from_filename=hint)
                
                if not original_domain:
                    result['error'] = '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–æ–º–µ–Ω'
                    return result
            
            result['original_domain'] = original_domain
            
            # 3.5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–∞–π—Ç–∞
            if progress_callback:
                progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {archive_name}: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–∞–π—Ç–∞...")
            
            original_site_name = self.site_name_replacer.detect_site_name(extract_dir, original_domain)
            
            if progress_callback:
                progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {archive_name}: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–æ–º–µ–Ω–æ–≤...")
            
            # 4. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤—ã–µ –¥–æ–º–µ–Ω—ã
            new_domains = self.domain_generator.generate_domains(
                original_domain, 
                copies_count, 
                domain_zone
            )
            
            # 5. –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–æ–≤–æ–≥–æ –¥–æ–º–µ–Ω–∞
            archives_created = []
            
            for idx, new_domain in enumerate(new_domains):
                if progress_callback:
                    progress_callback(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ {archive_name}: –∫–æ–ø–∏—è {idx+1}/{copies_count} ({new_domain})...")
                
                # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫–æ–ø–∏–∏
                copy_dir = os.path.join(archive_temp_dir, f"copy_{idx}")
                shutil.copytree(extract_dir, copy_dir)
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –Ω–æ–≤–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑ –Ω–æ–≤–æ–≥–æ –¥–æ–º–µ–Ω–∞
                new_site_name = self.site_name_replacer.generate_site_name_from_domain(new_domain)
                
                # –ó–∞–º–µ–Ω—è–µ–º –¥–æ–º–µ–Ω –∏ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å–∞–π—Ç–∞ –≤–æ –≤—Å–µ—Ö —Ñ–∞–π–ª–∞—Ö
                stats = self.file_processor.process_directory(
                    copy_dir, 
                    original_domain, 
                    new_domain,
                    original_site_name,
                    new_site_name
                )
                
                # –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏–≤ –∏–∑ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–π –∫–æ–ø–∏–∏
                archive_name_output = self.archive_handler.get_archive_name_from_domain(new_domain)
                archive_output_path = os.path.join(archive_temp_dir, archive_name_output)
                
                if self.archive_handler.create_zip_archive(copy_dir, archive_output_path):
                    archives_created.append({
                        'path': archive_output_path,
                        'domain': new_domain,
                        'stats': stats
                    })
                
                # –£–¥–∞–ª—è–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫–æ–ø–∏–∏ —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –º–µ—Å—Ç–æ
                self.archive_handler.cleanup_directory(copy_dir)
            
            # 6. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result['success'] = True
            result['generated_archives'] = archives_created
            result['stats'] = {
                'copies_created': len(archives_created),
                'original_domain': original_domain
            }
            
        except Exception as e:
            result['error'] = str(e)
        
        return result
    
    def process_multiple_archives(self, archives: List[str], copies_count: int,
                                  domain_zone: str, output_dir: str,
                                  progress_callback=None) -> Dict:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∞—Ä—Ö–∏–≤–æ–≤
        
        Args:
            archives: —Å–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∞—Ä—Ö–∏–≤–∞–º
            copies_count: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–æ–ø–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∞—Ä—Ö–∏–≤–∞
            domain_zone: –¥–æ–º–µ–Ω–Ω–∞—è –∑–æ–Ω–∞ (.com, .info)
            output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            progress_callback: —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
            
        Returns:
            dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤—Å–µ—Ö –∞—Ä—Ö–∏–≤–æ–≤
        """
        overall_result = {
            'success': False,
            'archives_processed': 0,
            'archives_failed': 0,
            'total_sites_created': 0,
            'master_archive_path': None,
            'results': [],
            'errors': []
        }
        
        try:
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            temp_base_dir = self.archive_handler.get_temp_dir()
            all_generated_archives = []
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –∞—Ä—Ö–∏–≤
            for idx, archive_path in enumerate(archives):
                if progress_callback:
                    progress_callback(f"–ê—Ä—Ö–∏–≤ {idx+1}/{len(archives)}: {os.path.basename(archive_path)}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤
                result = self.process_single_archive(
                    archive_path,
                    copies_count,
                    domain_zone,
                    temp_base_dir,
                    progress_callback
                )
                
                overall_result['results'].append(result)
                
                if result['success']:
                    overall_result['archives_processed'] += 1
                    overall_result['total_sites_created'] += len(result['generated_archives'])
                    
                    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–æ–∑–¥–∞–Ω–Ω—ã–µ –∞—Ä—Ö–∏–≤—ã
                    for archive_info in result['generated_archives']:
                        all_generated_archives.append(archive_info['path'])
                else:
                    overall_result['archives_failed'] += 1
                    overall_result['errors'].append({
                        'archive': os.path.basename(archive_path),
                        'error': result.get('error', 'Unknown error')
                    })
            
            if progress_callback:
                progress_callback("–°–æ–∑–¥–∞–Ω–∏–µ –≥–ª–∞–≤–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞...")
            
            # –°–æ–∑–¥–∞–µ–º –≥–ª–∞–≤–Ω—ã–π –∞—Ä—Ö–∏–≤ —Å–æ –≤—Å–µ–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            if all_generated_archives:
                os.makedirs(output_dir, exist_ok=True)
                
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                master_archive_name = f"duplicates_{timestamp}.zip"
                master_archive_path = os.path.join(output_dir, master_archive_name)
                
                if self.archive_handler.create_master_archive(all_generated_archives, master_archive_path):
                    overall_result['master_archive_path'] = master_archive_path
                    overall_result['success'] = True
            
            # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            if progress_callback:
                progress_callback("–û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
            
            self.archive_handler.cleanup_directory(temp_base_dir)
            
        except Exception as e:
            overall_result['errors'].append({
                'archive': 'general',
                'error': str(e)
            })
        
        return overall_result
    
    def get_summary_text(self, result: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—é–º–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        lines = []
        
        lines.append("=" * 50)
        lines.append("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò")
        lines.append("=" * 50)
        
        if result['success']:
            lines.append(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            lines.append(f"")
            lines.append(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            lines.append(f"  ‚Ä¢ –ê—Ä—Ö–∏–≤–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result['archives_processed']}")
            lines.append(f"  ‚Ä¢ –ê—Ä—Ö–∏–≤–æ–≤ —Å –æ—à–∏–±–∫–∞–º–∏: {result['archives_failed']}")
            lines.append(f"  ‚Ä¢ –í—Å–µ–≥–æ —Å–∞–π—Ç–æ–≤ —Å–æ–∑–¥–∞–Ω–æ: {result['total_sites_created']}")
            
            if result['master_archive_path']:
                lines.append(f"")
                lines.append(f"üì¶ –ì–ª–∞–≤–Ω—ã–π –∞—Ä—Ö–∏–≤:")
                lines.append(f"  {os.path.basename(result['master_archive_path'])}")
        else:
            lines.append(f"‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
        
        if result['errors']:
            lines.append(f"")
            lines.append(f"‚ö†Ô∏è –û—à–∏–±–∫–∏:")
            for error in result['errors']:
                lines.append(f"  ‚Ä¢ {error['archive']}: {error['error']}")
        
        lines.append("=" * 50)
        
        return "\n".join(lines)
